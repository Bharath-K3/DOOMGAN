# DOOMGAN: High-Fidelity Dynamic Identity Obfuscation Ocular Generative Morphing

[![Conference](https://img.shields.io/badge/IJCB-2025-blue)](https://ieee-biometrics.org/ijcb2024/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/release/python-3100/)

Official PyTorch implementation for our paper, **"DOOMGAN: High-Fidelity Dynamic Identity Obfuscation Ocular Generative Morphing"**, accepted at the IEEE International Joint Conference on Biometrics (IJCB) 2025.

**Authors:** Bharath Krishnamurthy and Ajita Rattani  
*University of North Texas*

---

<p align="center">
  <img src="assets/eye_morphing_comparison.png" width="800" alt="DOOMGAN Teaser">
  <br>
  <em>Figure 1: Illustration of morphed ocular images generated by our proposed DOOMGAN. A morphed image combines images of two different identities such that the ensuing biometric template can match both contributing subjects, posing a serious security threat.</em>
</p>

## Abstract

> Ocular biometrics in the visible spectrum have emerged as a prominent modality due to their high accuracy, resistance to spoofing, and non-invasive nature. Morphing attacks—where synthetic biometric traits are created by merging features from multiple individuals—pose a significant threat to the trustworthiness and integrity of biometric systems. While morphing attacks have been thoroughly investigated for the near-infrared iris and face biometrics, their implications for visible-spectrum ocular biometrics remain largely unexplored. Effectively simulating such attacks requires a sophisticated morphing generation model capable of handling the complexities of uncontrolled acquisition environments while preserving fine-grained ocular features. To address this gap, we introduce **DOOMGAN**, a novel framework that encompasses landmark-driven encoding, attention-guided generation, and dynamic weighting of multi-faceted losses for optimized convergence. We evaluated DOOMGAN against visible ocular recognition systems, achieving over 20% improvement in attack success rates over baseline models. Moreover, DOOMGAN shows a 20% boost in generating elliptical iris structures and a 30% boost in maintaining gaze consistency. Additionally, we provide the first comprehensive ocular morphing datasets to aid research in defending against such attacks.

---

## Key Contributions

-   **Novel Ocular Landmark Generator**: We introduce a landmark generator that surpasses existing models in precision, crucial for accurately morphing anatomical structures and ensuring robustness against gaze deviations.
-   **Specialized Ocular Morphing Model (DOOMGAN)**: A novel GAN-based framework designed specifically for synthesizing high-quality ocular morphs using landmark-driven encoding and attention-guided generation.
-   **Dynamic Weighting Scheme**: An innovative dynamic process to balance the contributions of a multi-faceted loss function, facilitating simultaneous and stable convergence during training.
-   **Novel Performance Metrics & Vulnerability Assessment**: We propose new ocular-specific metrics (Iris Irregularity and Gaze Direction) and perform a thorough vulnerability assessment against existing ocular recognition and morph attack detection (MAD) systems.
-   **First Public Ocular Morph Datasets**: We contribute extensive visible-light morphed ocular image datasets to facilitate future research in detecting and defending against these advanced attacks.

## Architecture Overview

DOOMGAN's architecture comprises five key components: a **Landmark Generator ($L_g$)**, a **Landmark Encoder ($L_e$)**, an **Image Encoder with Landmark Heatmaps ($E$)**, an **Attention-Based Landmark Guided Generator ($G$)**, and a **Spectral Normalization Powered Discriminator ($D$)**.

<p align="center">
  <img src="assets/Intro GAN.jpg" width="800" alt="DOOMGAN Architecture">
  <br>
  <em>Figure 2: The overall architecture of the proposed DOOMGAN for visible spectrum ocular morph generation.</em>
</p>

## Results

DOOMGAN consistently outperforms state-of-the-art landmark-based and GAN-based morphing models across all key metrics, including image quality (SSIM), anatomical correctness (IR, Gaze), and vulnerability (MMPMR, FMMPMR).

| Method             | SSIM          | IR              | Gaze            | MMPMR (0.01%) | FMMPMR (0.01%) |
| ------------------ | ------------- | --------------- | --------------- | ------------- | -------------- |
| LM (Baseline)      | **0.72**      | 0.7328          | 0.5916          | **92.50**     | 15.32          |
| MorGAN             | 0.46          | 0.5938          | 0.4716          | 3.92          | 0.01           |
| StyleGAN           | 0.47          | 0.6683          | 0.5080          | 4.60          | 0.11           |
| VAE-GAN            | 0.56          | 0.7099          | 0.6548          | 26.38         | 0.23           |
| MIPGAN             | 0.46          | 0.7723          | 0.5753          | 28.22         | 2.39           |
| MorCode            | 0.54          | 0.7826          | 0.7577          | 32.42         | 3.84           |
| **DOOMGAN (Ours)** | 0.67          | **0.9380**      | **0.9775**      | 75.00         | **30.95**      |

*Table 1: Comparative evaluation against baseline models on the VISOB dataset with the OVS-I system. DOOMGAN shows superior anatomical correctness and a significantly higher fully-mated attack rate (FMMPMR).*

### Qualitative Results

<p align="center">
  <img src="assets/Final_Morph_Compare.jpg" width="800" alt="Qualitative Comparison">
  <br>
  <em>Figure 3: Qualitative comparison showing DOOMGAN's superior ability to handle uncontrolled environments (off-angle iris, pose variation) compared to baseline methods.</em>
</p>

---

## Installation

Follow these instructions to set up a dedicated environment for running this project, ensuring all dependencies are handled correctly.

### Prerequisites

*   **Anaconda or Miniconda:** You must have a working installation of Conda.
*   **Git:** To clone the repository.
*   **(Optional) NVIDIA GPU:** For significantly faster training and inference.

### Step-by-Step Setup

1.  **Clone the Repository**

    Open your terminal or command prompt and clone this project:
    ```bash
    git clone https://github.com/Bharath-K3/DOOMGAN.git
    cd DOOMGAN
    ```

2.  **Create and Activate the Conda Environment**

    We will create a new Conda environment named `doomgan` with Python 3.10 to ensure consistency.

    ```bash
    # Create the environment named 'doomgan' with Python 3.10
    conda create -n doomgan python=3.10 -y

    # Activate the new environment
    conda activate doomgan
    ```
    Your terminal prompt should now begin with `(doomgan)`.

3.  **Install Dependencies**

    With the `doomgan` environment active, install all required libraries using the provided `requirements.txt` file.

    ```bash
    pip install -r requirements.txt
    ```

4.  **Download Pre-trained Models**

    This project requires pre-trained model weights to function. Please download the following and place them in the correct directories as specified in `config/config.yaml`:

    *   **Your trained GAN models** (Generator, Encoder, etc.) into their respective output directories (e.g., `generator_models/`).
    *   **The pre-trained ArcFace model** (for identity loss during training).
    *   **The pre-trained Landmark Predictor model** (for the web applications and generation scripts).

---

## Usage

### 1. Training the Model

Before training, configure your dataset paths and hyperparameters in `config/config.yaml`. Log in to your Weights & Biases account for experiment tracking.

```bash
# Login to W&B (optional but recommended)
wandb login

# Run the training script
python train.py
```

### 2. Generating Morphs via Command Line
Use the generate_morphs.py script to create a morphed image from two source images.

```bash
python generate_morphs.py --image1 "path/to/your/image1.png" --image2 "path/to/your/image2.png" --epoch 500 --output "generated_morphs/output.png"
```

Below is an example run

```bash
python generate_morphs.py --image1 "assets/1144_r_1.png" --image2 "assets/1147_r_1.png" --epoch 450 --output "generated_morphs/1144_1147.png"
```

### 3. Running the Web Applications
We provide two interactive web applications for easy demonstration.

```bash
To launch the Streamlit app:
streamlit run app.py

To launch the Gradio app:
python app.py
```

## Citation
If you find our work useful in your research, please consider citing our paper:
```bib

````